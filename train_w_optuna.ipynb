{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hydra\n",
    "import pytorch_lightning as pl\n",
    "from contrib.eeg.solvers import *\n",
    "from torch.optim import Adam\n",
    "import optuna\n",
    "\n",
    "os.environ['HYDRA_FULL_ERROR'] = \"1\"\n",
    "with hydra.initialize(config_path=\"config\", version_base=None):\n",
    "    cfg = hydra.compose(\"config_global\",\n",
    "                        overrides=[\n",
    "                            'datamodule.dataset_kw.to_load=10000', \n",
    "                            'datamodule.dl_kw.batch_size=32',\n",
    "                            #'datamodule.dataset_kw.simu_name=_dl_ses_fsaverage_st1020_',\n",
    "                            'datamodule.subset_name=none',\n",
    "                            ])\n",
    "\n",
    "pl.seed_everything(333) # seed for reproducibility\n",
    "\n",
    "# Data\n",
    "dm = hydra.utils.call(cfg.datamodule)\n",
    "dm.setup(\"train\")\n",
    "\n",
    "# Hyperparameters with Optuna\n",
    "prior_ponde = trial.suggest_float(\"prior_ponde\", 1e-2, 1e2, log=True)\n",
    "lr_grad = trial.suggest_float(\"lr_grad\", 1e-12, 1e-6, log=True)\n",
    "Lambda = trial.suggest_float(\"Lambda\", 1e-2, 1e1, log=True)\n",
    "\n",
    "# Model\n",
    "solver = EsiGradSolver_n(fwd=hydra.utils.call(cfg.fwd), n_step=10,\n",
    "                        prior_cost=hydra.utils.call(cfg.prior_cost),\n",
    "                        obs_cost=hydra.utils.call(cfg.obs_cost),\n",
    "                        grad_mod=hydra.utils.call(cfg.grad_mod),\n",
    "                        \n",
    "                        # Search with Optuna\n",
    "                        prior_ponde=prior_ponde,\n",
    "                        lr_grad=lr_grad)\n",
    "litmodel = EsiLitModule(solver=solver, opt_fn=Adam, lr=5e-5,\n",
    "                        loss_fn=hydra.utils.call(cfg.cost_functions.train_cost_fn), Lambda=Lambda)\n",
    "# print(litmodel)\n",
    "# for k, p in litmodel.named_parameters():\n",
    "#     print(f\"{k}: {p.numel()}\")\n",
    "# print(sum(p.numel() for p in litmodel.parameters() if p.requires_grad))\n",
    "\n",
    "# Trainer\n",
    "trainer = hydra.utils.call(cfg.trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
